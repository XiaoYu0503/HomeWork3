"""Streamlit Demo for SMS Spam Classifier.
Run:
  streamlit run spam_classifier/streamlit_app.py
"""
from __future__ import annotations
import os
from typing import Optional, List

import pandas as pd
import joblib
import streamlit as st
import numpy as np
import matplotlib.pyplot as plt
from io import BytesIO
from wordcloud import WordCloud
from sklearn.metrics import confusion_matrix, roc_curve, auc

# èˆ‡è¨“ç·´è…³æœ¬è¼¸å‡ºä¸€è‡´ï¼šæ¨¡å‹ä½æ–¼å°ˆæ¡ˆæ ¹ç›®éŒ„ä¸‹ models/spam_model.joblib
MODEL_PATH = os.path.join("models", "spam_model.joblib")
DATA_FILE = "sms_spam_no_header.csv"

@st.cache_resource(show_spinner=False)
def load_model() -> Optional[object]:
    if not os.path.exists(MODEL_PATH):
        return None
    return joblib.load(MODEL_PATH)

@st.cache_data(show_spinner=False)
def load_dataset(path: str) -> Optional[pd.DataFrame]:
    if not os.path.exists(path):
        return None
    # è³‡æ–™ç‚ºç„¡è¡¨é ­ä¸”å«å¼•è™Ÿï¼ŒæŒ‡å®š header=None èˆ‡æ¬„ä½åç¨±
    df = pd.read_csv(path, encoding="utf-8", header=None, names=["label", "text"])
    df = df.dropna(subset=["text"]).copy()
    df["text"] = df["text"].astype(str)
    return df

st.set_page_config(page_title="SMS Spam Classifier", page_icon="ğŸ“¨", layout="wide")
st.title("ğŸ“¨ SMS åƒåœ¾ç°¡è¨Šåˆ†é¡å™¨ Demo")

model = load_model()
if model is None:
    st.error("æ¨¡å‹å°šæœªå»ºç«‹ï¼Œè«‹å…ˆåœ¨æ ¹ç›®éŒ„åŸ·è¡Œ: python .\\spam_classifier\\train.py")
    st.stop()

dataset = load_dataset(DATA_FILE)
if dataset is None:
    st.warning("æ‰¾ä¸åˆ°è³‡æ–™æª” sms_spam_no_header.csvï¼Œè³‡æ–™è¦–è¦ºåŒ–åŠŸèƒ½å°‡åœç”¨ã€‚")

with st.sidebar:
    st.header("è¨­å®š")
    show_prob = st.checkbox("é¡¯ç¤ºæ‰€æœ‰é¡åˆ¥æ©Ÿç‡", True)
    batch_limit = st.number_input("æ‰¹æ¬¡é æ¸¬é¡¯ç¤ºç­†æ•¸ä¸Šé™", min_value=5, max_value=200, value=50, step=5)
    top_n_terms = st.slider("Top æ¬Šé‡è©é¡¯ç¤ºæ•¸é‡", min_value=5, max_value=50, value=20, step=5)
    show_wordcloud = st.checkbox("é¡¯ç¤ºè©é›² (WordCloud)", True)
    st.markdown("---")
    st.markdown("**æ¨¡å‹è·¯å¾‘**: ``{}``".format(MODEL_PATH))

# å–®ç­†è¼¸å…¥
st.subheader("å–®ç­†è¨Šæ¯é æ¸¬")
text = st.text_area("è¼¸å…¥ç°¡è¨Šå…§å®¹ï¼š", height=120, placeholder="ä¾‹å¦‚ï¼šFree entry in a weekly cash prize draw")
col_predict, col_clear = st.columns([1,1])
if col_predict.button("ğŸ”® é æ¸¬"):
    if not text.strip():
        st.warning("è«‹è¼¸å…¥è¨Šæ¯å…§å®¹ã€‚")
    else:
        pred = model.predict([text])[0]
        proba = model.predict_proba([text])[0]
        classes = list(model.classes_)
        prob_map = dict(zip(classes, proba))
        is_spam = pred.lower() == "spam"
        color = "#d9534f" if is_spam else "#5cb85c"
        st.markdown(f"<div style='padding:12px;border-radius:6px;background:{color};color:#fff;font-weight:bold;'>åˆ†é¡çµæœï¼š {pred.upper()}</div>", unsafe_allow_html=True)
        if show_prob:
            df_prob = pd.DataFrame({"class": classes, "probability": proba}).sort_values("probability", ascending=False)
            st.table(df_prob)
if col_clear.button("ğŸ§¹ æ¸…é™¤"):
    st.experimental_set_query_params()  # ç®€å–®åˆ·æ–°

st.markdown("---")

# æ‰¹æ¬¡ä¸Šå‚³
st.subheader("æ‰¹æ¬¡é æ¸¬ (CSV ä¸Šå‚³)")
st.caption("æ ¼å¼ï¼šç„¡è¡¨é ­ï¼Œç¬¬ä¸€æ¬„ label(å¯ç•™ç©º)ã€ç¬¬äºŒæ¬„ textã€‚è‹¥å·²æœ‰è¡¨é ­äº¦å¯ä¸Šå‚³ï¼Œç¨‹å¼æœƒå˜—è©¦è¾¨è­˜ã€‚")
uploaded = st.file_uploader("é¸æ“‡ CSV æª”", type=["csv"]) 
if uploaded is not None:
    try:
        # å˜—è©¦è®€å–ï¼šå…ˆå˜—è©¦å«è¡¨é ­ï¼Œä¸è¡Œå‰‡æŒ‡å®šæ¬„ä½
        try:
            df_up = pd.read_csv(uploaded)
            if set(df_up.columns) >= {"label", "text"}:
                pass
            elif df_up.shape[1] >= 2:
                df_up = pd.read_csv(uploaded, header=None, names=["label", "text"])
            else:
                st.error("CSV æ¬„ä½ä¸è¶³ï¼Œéœ€è‡³å°‘ 2 æ¬„ã€‚")
                df_up = None
        except Exception:
            uploaded.seek(0)
            df_up = pd.read_csv(uploaded, header=None, names=["label", "text"])
        if df_up is not None:
            df_up = df_up.dropna(subset=["text"]).head(batch_limit)
            preds = model.predict(df_up["text"].astype(str))
            probas = model.predict_proba(df_up["text"].astype(str))
            classes = list(model.classes_)
            df_result = df_up.copy()
            df_result["pred"] = preds
            # å– spam æ©Ÿç‡ä»¥ä¾¿æ’åºï¼ˆå‡è¨­å­˜åœ¨ spam é¡åˆ¥ï¼‰
            if "spam" in classes:
                spam_index = classes.index("spam")
                df_result["spam_prob"] = [p[spam_index] for p in probas]
            if show_prob:
                # å±•é–‹å„é¡åˆ¥æ©Ÿç‡
                for ci, cname in enumerate(classes):
                    df_result[f"prob_{cname}"] = [p[ci] for p in probas]
            st.write(df_result)
            st.success(f"å®Œæˆ {len(df_result)} ç­†é æ¸¬ã€‚")
    except Exception as e:
        st.error(f"è®€å–æˆ–é æ¸¬æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")

st.markdown("---")

# è³‡æ–™é›†è¦–è¦ºåŒ–
st.subheader("è³‡æ–™æ¢ç´¢ / è¦–è¦ºåŒ–")
if dataset is not None:
    with st.expander("åŸå§‹è³‡æ–™å‰ 10 ç­†"):
        st.dataframe(dataset.head(10))

    col_a, col_b, col_c = st.columns(3)
    # æ¨™ç±¤åˆ†ä½ˆ
    label_counts = dataset["label"].value_counts()
    col_a.metric("ç¸½ç­†æ•¸", f"{len(dataset):,}")
    col_a.write(label_counts)
    # é•·åº¦ç›´æ–¹åœ–
    fig_len, ax_len = plt.subplots(figsize=(4,3))
    ax_len.hist(dataset["length"], bins=40, color="#4e79a7", alpha=0.85)
    ax_len.set_title("è¨Šæ¯é•·åº¦ç›´æ–¹åœ–")
    ax_len.set_xlabel("å­—å…ƒæ•¸")
    ax_len.set_ylabel("é »ç‡")
    col_b.pyplot(fig_len, clear_figure=True)

    # è¨Šæ¯é•·åº¦åˆ†ä½ˆ
    dataset["length"] = dataset["text"].str.len()
    col_b.caption("è¨Šæ¯é•·åº¦åˆ†ä½ˆ (éƒ¨åˆ†çµ±è¨ˆ)")
    col_b.write(dataset["length"].describe())

    # Top TF-IDF è©å½™ï¼ˆç°¡æ˜“ï¼šæ“·å–æ¨¡å‹å‘é‡å™¨ç‰¹å¾µ + spam é¡åˆ¥å°æ‡‰çš„ LogisticRegression æ¬Šé‡ï¼‰
    try:
        if hasattr(model, "named_steps") and "tfidf" in model.named_steps and "clf" in model.named_steps:
            vect = model.named_steps["tfidf"]
            clf = model.named_steps["clf"]
            feature_names: List[str] = list(vect.get_feature_names_out())
            if len(clf.classes_) == 2:
                spam_index = list(clf.classes_).index("spam")
                # Binary logistic regression coef_ shape could be (1, n_features)
                if clf.coef_.shape[0] == 1:
                    weights_spam = clf.coef_[0]
                    weights_ham = -clf.coef_[0]  # approximate opposite
                else:
                    weights_spam = clf.coef_[spam_index]
                    ham_index = 1 - spam_index
                    weights_ham = clf.coef_[ham_index]
                # Top spam
                spam_top_idx = np.argsort(weights_spam)[::-1][:top_n_terms]
                ham_top_idx = np.argsort(weights_ham)[::-1][:top_n_terms]
                df_spam_top = pd.DataFrame([(feature_names[i], float(weights_spam[i])) for i in spam_top_idx], columns=["term","weight"]) 
                df_ham_top = pd.DataFrame([(feature_names[i], float(weights_ham[i])) for i in ham_top_idx], columns=["term","weight"]) 
                st.markdown("### é¡åˆ¥é—œéµè© Top æ’è¡Œ")
                col_spam, col_ham = st.columns(2)
                col_spam.caption("Spam Top è©å½™")
                col_spam.table(df_spam_top)
                col_ham.caption("Ham Top è©å½™")
                col_ham.table(df_ham_top)
                # è©é›²
                if show_wordcloud:
                    st.markdown("### è©é›²è¦–è¦ºåŒ–")
                    spam_text = " ".join(dataset[dataset.label.str.lower()=="spam"]["text"].tolist())
                    ham_text = " ".join(dataset[dataset.label.str.lower()=="ham"]["text"].tolist())
                    wc_spam = WordCloud(width=600, height=400, background_color="white").generate(spam_text)
                    wc_ham = WordCloud(width=600, height=400, background_color="white").generate(ham_text)
                    col_w1, col_w2 = st.columns(2)
                    col_w1.image(wc_spam.to_array(), caption="Spam è©é›²", use_column_width=True)
                    col_w2.image(wc_ham.to_array(), caption="Ham è©é›²", use_column_width=True)
    except Exception as e:
        st.info(f"ç„¡æ³•è¨ˆç®—è©å½™æ’è¡Œæ¦œ/è©é›²: {e}")

    # æ··æ·†çŸ©é™£ & ROC
    st.markdown("### è©•ä¼° (æ•´ä»½è³‡æ–™é›†é‡è·‘æ¨è«–)")
    try:
        y_true = dataset["label"].astype(str)
        y_pred_full = model.predict(dataset["text"].astype(str))
        cm = confusion_matrix(y_true, y_pred_full, labels=["ham","spam"])
        fig_cm, ax_cm = plt.subplots(figsize=(4,3))
        im = ax_cm.imshow(cm, cmap="Blues")
        ax_cm.set_xticks([0,1]); ax_cm.set_xticklabels(["ham","spam"])
        ax_cm.set_yticks([0,1]); ax_cm.set_yticklabels(["ham","spam"])
        ax_cm.set_xlabel("Predicted"); ax_cm.set_ylabel("Actual")
        for (i,j), v in np.ndenumerate(cm):
            ax_cm.text(j, i, str(v), ha="center", va="center", color="black")
        ax_cm.set_title("Confusion Matrix")
        st.pyplot(fig_cm, clear_figure=True)

        # ROC (spam as positive)
        if hasattr(model, "predict_proba"):
            proba_full = model.predict_proba(dataset["text"].astype(str))
            classes = list(model.classes_)
            if "spam" in classes:
                spam_index = classes.index("spam")
                spam_scores = proba_full[:, spam_index]
                y_bin = (y_true.str.lower()=="spam").astype(int)
                fpr, tpr, _ = roc_curve(y_bin, spam_scores)
                roc_auc = auc(fpr, tpr)
                fig_roc, ax_roc = plt.subplots(figsize=(4,3))
                ax_roc.plot(fpr, tpr, label=f"ROC AUC={roc_auc:.3f}")
                ax_roc.plot([0,1],[0,1], linestyle="--", color="gray")
                ax_roc.set_xlabel("FPR")
                ax_roc.set_ylabel("TPR")
                ax_roc.set_title("ROC Curve (spam as positive)")
                ax_roc.legend(loc="lower right")
                st.pyplot(fig_roc, clear_figure=True)
    except Exception as e:
        st.info(f"è©•ä¼°è¨ˆç®—å¤±æ•—: {e}")

    # ä¸‹è¼‰æ•´é«”é æ¸¬çµæœ
    try:
        st.markdown("### åŒ¯å‡ºé æ¸¬çµæœ")
        full_df = dataset.copy()
        full_df["pred"] = y_pred_full
        if "spam_scores" in locals():
            full_df["spam_prob"] = spam_scores
        csv_bytes = full_df.to_csv(index=False).encode("utf-8-sig")
        st.download_button("ä¸‹è¼‰å®Œæ•´é æ¸¬çµæœ CSV", data=csv_bytes, file_name="spam_predictions.csv", mime="text/csv")
    except Exception as e:
        st.info(f"ç„¡æ³•ç”¢ç”Ÿä¸‹è¼‰ï¼š{e}")
else:
    st.info("è³‡æ–™æª”ç¼ºå¤±ï¼Œåƒ…èƒ½ä½¿ç”¨é æ¸¬åŠŸèƒ½ã€‚")

st.markdown("---")
with st.expander("èªªæ˜ / Help"):
    st.markdown(
        """
        **ä½¿ç”¨èªªæ˜**
        - å–®ç­†è¼¸å…¥å€è¼¸å…¥è¨Šæ¯å¾ŒæŒ‰ä¸‹ã€é æ¸¬ã€ã€‚
        - æ‰¹æ¬¡ä¸Šå‚³æ”¯æ´ CSVï¼Œå‰å…©æ¬„è¦–ç‚º label èˆ‡ textï¼›label å¯ç‚ºç©ºç”¨æ–¼æ¨è«–ã€‚
        - è‹¥å°šæœªè¨“ç·´æ¨¡å‹ï¼Œè«‹å…ˆåœ¨å°ˆæ¡ˆæ ¹ç›®éŒ„åŸ·è¡Œï¼š`python .\\spam_classifier\\train.py`ã€‚
        **æ”¹é€²å»ºè­°**
        - å¯å¢åŠ è³‡æ–™æ¸…ç†ï¼ˆURLã€è¡¨æƒ…ç¬¦è™Ÿæ­£è¦åŒ–ï¼‰ã€‚
        - å¯æ›¿æ›æ¨¡å‹ç‚º SVCã€Naive Bayes æˆ–æ·±åº¦å­¸ç¿’ã€‚
        - å¯åŠ å…¥æ··æ·†çŸ©é™£èˆ‡ ROC æ›²ç·šè¦–è¦ºåŒ–ã€‚
        """
    )
